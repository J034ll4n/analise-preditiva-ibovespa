{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90749f9e",
   "metadata": {},
   "source": [
    "## Visualização e Correção de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daba4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44df0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'Ibovespa_Consolidado.csv' carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# --- Carregar o Dataset ---\n",
    "try:\n",
    "    df = pd.read_csv('Ibovespa_Consolidado.csv')\n",
    "    print(\"Arquivo 'Ibovespa_Consolidado.csv' carregado com sucesso!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: O arquivo 'Ibovespa_Consolidado.csv' não foi encontrado.\")\n",
    "    print(\"Verifique se o nome do arquivo está correto e se ele está na mesma pasta que este script.\")\n",
    "    exit() # Encerra o script se o arquivo não for encontrado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf9adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Visualização Inicial do Dataset ---\n",
      "\n",
      "Primeiras 5 linhas do dataset:\n",
      "         Data  Último  Abertura  Máxima  Mínima     Vol.    Var%\n",
      "0  01.08.2000  16.290    16.475  16.591  16.127  123,64M  -1,00%\n",
      "1  31.07.2000  16.455    16.487  16.713  16.455  705,80M  -0,19%\n",
      "2  28.07.2000  16.486    16.949  17.039  16.448  102,09M  -2,73%\n",
      "3  27.07.2000  16.949    17.121  17.225  16.923  110,50M  -1,00%\n",
      "4  26.07.2000  17.121    17.049  17.211  16.840  123,20M   0,42%\n",
      "\n",
      "Informações gerais do dataset (tipos de dados, valores nulos):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10756 entries, 0 to 10755\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Data      10756 non-null  object \n",
      " 1   Último    10756 non-null  float64\n",
      " 2   Abertura  10756 non-null  float64\n",
      " 3   Máxima    10756 non-null  float64\n",
      " 4   Mínima    10756 non-null  float64\n",
      " 5   Vol.      10755 non-null  object \n",
      " 6   Var%      10756 non-null  object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 588.3+ KB\n",
      "\n",
      "Contagem de valores nulos por coluna:\n",
      "Data        0\n",
      "Último      0\n",
      "Abertura    0\n",
      "Máxima      0\n",
      "Mínima      0\n",
      "Vol.        1\n",
      "Var%        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- . Visualização Inicial dos Dados ---\n",
    "print(\"\\n--- Visualização Inicial do Dataset ---\")\n",
    "print(\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nInformações gerais do dataset (tipos de dados, valores nulos):\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nContagem de valores nulos por coluna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb62c370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Limpeza e Conversão de Tipos ---\n",
      "\n",
      "Coluna 'Data' convertida para o formato datetime.\n",
      "\n",
      "Convertendo colunas para formato numérico...\n",
      "Coluna 'Último' já está em formato numérico. Apenas garantindo que seja float.\n",
      "Coluna 'Abertura' já está em formato numérico. Apenas garantindo que seja float.\n",
      "Coluna 'Máxima' já está em formato numérico. Apenas garantindo que seja float.\n",
      "Coluna 'Mínima' já está em formato numérico. Apenas garantindo que seja float.\n",
      "Colunas ['Último', 'Abertura', 'Máxima', 'Mínima'] foram processadas com sucesso.\n",
      "Coluna 'Var%' convertida para formato numérico (float) e dividida por 100.\n",
      "Coluna 'Vol.' convertida para formato numérico.\n"
     ]
    }
   ],
   "source": [
    "# --- . Limpeza e Conversão de Tipos ---\n",
    "print(\"\\n--- Iniciando Limpeza e Conversão de Tipos ---\")\n",
    "\n",
    "# a) Converter a coluna 'Data' para o formato de data (datetime)\n",
    "# O formato atual é dia.mês.ano ('%d.%m.%Y')\n",
    "df['Data'] = pd.to_datetime(df['Data'], format='%d.%m.%Y')\n",
    "print(\"\\nColuna 'Data' convertida para o formato datetime.\")\n",
    "\n",
    "# b) Limpar e converter colunas numéricas ('Último', 'Abertura', 'Máxima', 'Mínima')\n",
    "# Essas colunas estão como strings (object) e usam '.' como separador de milhar.\n",
    "colunas_numericas = ['Último', 'Abertura', 'Máxima', 'Mínima']\n",
    "print(\"\\nConvertendo colunas para formato numérico...\")\n",
    "\n",
    "for coluna in colunas_numericas:\n",
    "    # VERIFICAÇÃO: O dtype 'object' é como o pandas representa colunas de texto.\n",
    "    if df[coluna].dtype == 'object':\n",
    "        # Se for texto, removemos o '.' e convertemos para float.\n",
    "        print(f\"Limpando e convertendo a coluna '{coluna}' (era texto)...\")\n",
    "        df[coluna] = df[coluna].str.replace('.', '', regex=False).astype(float)\n",
    "    else:\n",
    "        # Se JÁ for um número, apenas garantimos que está como float.\n",
    "        print(f\"Coluna '{coluna}' já está em formato numérico. Apenas garantindo que seja float.\")\n",
    "        df[coluna] = df[coluna].astype(float)\n",
    "\n",
    "print(f\"Colunas {colunas_numericas} foram processadas com sucesso.\")\n",
    "\n",
    "# c) Limpar e converter a coluna 'Var%'\n",
    "# Está como string, com ',' para decimal e '%' no final.\n",
    "df['Var%'] = df['Var%'].str.replace(',', '.', regex=False).str.replace('%', '', regex=False).astype(float) / 100\n",
    "print(\"Coluna 'Var%' convertida para formato numérico (float) e dividida por 100.\")\n",
    "\n",
    "# d) Limpar e converter a coluna 'Vol.' (Volume)\n",
    "# É uma string com 'B' para bilhões e 'M' para milhões, e ',' como decimal.\n",
    "def converter_volume(volume_str):\n",
    "    if isinstance(volume_str, str):\n",
    "        volume_str = volume_str.strip().upper()\n",
    "        volume_str = volume_str.replace(',', '.')\n",
    "        if 'B' in volume_str:\n",
    "            return float(volume_str.replace('B', '')) * 1_000_000_000\n",
    "        elif 'M' in volume_str:\n",
    "            return float(volume_str.replace('M', '')) * 1_000_000\n",
    "        elif 'K' in volume_str:\n",
    "             return float(volume_str.replace('K', '')) * 1_000\n",
    "    return volume_str\n",
    "\n",
    "df['Vol.'] = df['Vol.'].apply(converter_volume)\n",
    "# Converte a coluna para numérico, e os valores que não puderam ser convertidos viram NaN (Not a Number)\n",
    "df['Vol.'] = pd.to_numeric(df['Vol.'], errors='coerce')\n",
    "print(\"Coluna 'Vol.' convertida para formato numérico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187eca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tratando Valores Nulos (NaN) ---\n",
      "\n",
      "Valores nulos antes do tratamento:\n",
      "Data        0\n",
      "Último      0\n",
      "Abertura    0\n",
      "Máxima      0\n",
      "Mínima      0\n",
      "Vol.        1\n",
      "Var%        0\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos depois do tratamento:\n",
      "Data        0\n",
      "Último      0\n",
      "Abertura    0\n",
      "Máxima      0\n",
      "Mínima      0\n",
      "Vol.        0\n",
      "Var%        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zirn\\AppData\\Local\\Temp\\ipykernel_38980\\4108165767.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[colunas_para_preencher] = df[colunas_para_preencher].fillna(method='ffill')\n",
      "C:\\Users\\zirn\\AppData\\Local\\Temp\\ipykernel_38980\\4108165767.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[colunas_para_preencher] = df[colunas_para_preencher].fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# --- . Tratamento de Valores Nulos (NaN) ---\n",
    "print(\"\\n--- Tratando Valores Nulos (NaN) ---\")\n",
    "print(f\"\\nValores nulos antes do tratamento:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Para dados de séries temporais, uma boa estratégia é preencher os valores ausentes\n",
    "# com o último valor válido conhecido (forward fill).\n",
    "# Isso é especialmente útil para preços de ações (Abertura, Máxima, etc.)\n",
    "colunas_para_preencher = ['Último', 'Abertura', 'Máxima', 'Mínima', 'Vol.', 'Var%']\n",
    "df[colunas_para_preencher] = df[colunas_para_preencher].fillna(method='ffill')\n",
    "\n",
    "# Se ainda sobrar algum NaN no início do dataset, podemos usar o backfill\n",
    "df[colunas_para_preencher] = df[colunas_para_preencher].fillna(method='bfill')\n",
    "\n",
    "print(f\"\\nValores nulos depois do tratamento:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fefd9499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verificando se existem datas duplicadas ---\n",
      "\n",
      "ATENÇÃO: Foram encontradas datas duplicadas!\n",
      "Abaixo estão as linhas com datas repetidas:\n",
      "            Último  Abertura  Máxima  Mínima         Vol.  Var%\n",
      "Data                                                           \n",
      "2000-08-01   16.29    16.475  16.591  16.127  123640000.0 -0.01\n",
      "2000-08-01   16.29    16.475  16.591  16.127  123640000.0 -0.01\n",
      "\n",
      "Removendo as datas duplicadas e mantendo o último registro de cada data...\n",
      "Duplicatas removidas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# ---  Verificar e Tratar Datas Duplicadas ---\n",
    "print(\"\\n--- Verificando se existem datas duplicadas ---\")\n",
    "\n",
    "# A propriedade `index.duplicated()` cria uma série booleana (True/False).\n",
    "# `keep=False` marca TODAS as ocorrências de uma duplicata como True.\n",
    "duplicatas = df.index.duplicated(keep=False)\n",
    "\n",
    "# .any() verifica se existe algum valor True na série de duplicatas\n",
    "if duplicatas.any():\n",
    "    print(f\"\\nATENÇÃO: Foram encontradas datas duplicadas!\")\n",
    "    # df[duplicatas] filtra o dataframe para mostrar apenas as linhas onde o índice é duplicado.\n",
    "    print(\"Abaixo estão as linhas com datas repetidas:\")\n",
    "    print(df[duplicatas])\n",
    "\n",
    "    # --- Tratamento das duplicatas ---\n",
    "    # A abordagem mais comum para dados financeiros é manter o último registro do dia.\n",
    "    print(\"\\nRemovendo as datas duplicadas e mantendo o último registro de cada data...\")\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    \n",
    "    print(\"Duplicatas removidas com sucesso.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Ótima notícia: Nenhuma data duplicada foi encontrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94a479da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Organizando o Dataset ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Data'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_38980\\1659422808.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- . Organização Final do Dataset ---\u001b[39;00m\n\u001b[32m      2\u001b[39m print(\u001b[33m\"\\n--- Organizando o Dataset ---\"\u001b[39m)\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# a) Definir a coluna 'Data' como o índice do dataframe\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = df.set_index(\u001b[33m'Data'\u001b[39m)\n\u001b[32m      6\u001b[39m print(\u001b[33m\"\\nColuna 'Data' definida como o novo índice do dataframe.\"\u001b[39m)\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# b) Ordenar o dataframe pela data (do mais antigo para o mais novo)\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\zirn\\Desktop\\programador\\fase2_techChallenge\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, keys, drop, append, inplace, verify_integrity)\u001b[39m\n\u001b[32m   6125\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m found:\n\u001b[32m   6126\u001b[39m                         missing.append(col)\n\u001b[32m   6127\u001b[39m \n\u001b[32m   6128\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m-> \u001b[39m\u001b[32m6129\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(f\"None of {missing} are in the columns\")\n\u001b[32m   6130\u001b[39m \n\u001b[32m   6131\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   6132\u001b[39m             frame = self\n",
      "\u001b[31mKeyError\u001b[39m: \"None of ['Data'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# --- . Organização Final do Dataset ---\n",
    "print(\"\\n--- Organizando o Dataset ---\")\n",
    "\n",
    "# a) Definir a coluna 'Data' como o índice do dataframe\n",
    "df = df.set_index('Data')\n",
    "print(\"\\nColuna 'Data' definida como o novo índice do dataframe.\")\n",
    "\n",
    "# b) Ordenar o dataframe pela data (do mais antigo para o mais novo)\n",
    "df = df.sort_index(ascending=True)\n",
    "print(\"Dataset ordenado pela data em ordem crescente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40756970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Visualização Final do Dataset Limpo ---\n",
      "\n",
      "Primeiras 5 linhas do dataset limpo e organizado:\n",
      "            Último  Abertura  Máxima  Mínima         Vol.  Var%\n",
      "Data                                                           \n",
      "1982-01-07     0.0       0.0     0.0     0.0  116090000.0   0.0\n",
      "1982-01-08     0.0       0.0     0.0     0.0  329760000.0   0.0\n",
      "1982-01-11     0.0       0.0     0.0     0.0  127520000.0   0.0\n",
      "1982-01-12     0.0       0.0     0.0     0.0  122620000.0   0.0\n",
      "1982-01-13     0.0       0.0     0.0     0.0  106190000.0   0.0\n",
      "\n",
      "Últimas 5 linhas do dataset limpo e organizado:\n",
      "             Último  Abertura   Máxima   Mínima          Vol.    Var%\n",
      "Data                                                                 \n",
      "2025-07-28  132.129   133.538  133.902  131.550  6.630000e+09 -0.0104\n",
      "2025-07-29  132.726   132.130  133.346  132.130  6.320000e+09  0.0045\n",
      "2025-07-30  133.990   132.702  134.368  131.883  8.660000e+09  0.0095\n",
      "2025-07-31  133.071   133.987  133.987  132.096  9.200000e+09 -0.0069\n",
      "2025-08-01  132.437   132.920  133.237  132.140  8.500000e+09 -0.0048\n",
      "\n",
      "Informações finais do dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 10756 entries, 1982-01-07 to 2025-08-01\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Último    10756 non-null  float64\n",
      " 1   Abertura  10756 non-null  float64\n",
      " 2   Máxima    10756 non-null  float64\n",
      " 3   Mínima    10756 non-null  float64\n",
      " 4   Vol.      10756 non-null  float64\n",
      " 5   Var%      10756 non-null  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 588.2 KB\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Visualização do Dataset Limpo ---\n",
    "print(\"\\n--- Visualização Final do Dataset Limpo ---\")\n",
    "print(\"\\nPrimeiras 5 linhas do dataset limpo e organizado:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nÚltimas 5 linhas do dataset limpo e organizado:\")\n",
    "print(df.tail())\n",
    "\n",
    "print(\"\\nInformações finais do dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6deb4af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processo Finalizado! ---\n",
      "O dataset limpo e organizado foi salvo como 'Ibovespa.csv'.\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Salvar o Dataset Limpo ---\n",
    "nome_arquivo_limpo = 'Ibovespa.csv'\n",
    "df.to_csv(nome_arquivo_limpo)\n",
    "print(f\"\\n--- Processo Finalizado! ---\")\n",
    "print(f\"O dataset limpo e organizado foi salvo como '{nome_arquivo_limpo}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e79de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
